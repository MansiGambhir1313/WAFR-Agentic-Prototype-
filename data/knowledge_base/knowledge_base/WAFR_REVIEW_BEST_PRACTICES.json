{
  "knowledge_base": {
    "source": "AWS Blog - How to perform a Well-Architected Framework Review - Part 2",
    "url": "https://aws.amazon.com/blogs/mt/how-to-perform-a-well-architected-framework-review-part2/",
    "author": "Ebrahim (EB) Khiyami, Senior Solutions Architect, AWS",
    "date": "August 3, 2023",
    "series": "Part 2 of 3 (Review Phase)",
    "last_updated": "2025-12-17",
    "version": "1.0",
    "description": "Best practices and lessons learned from conducting Well-Architected Framework Reviews with customers across different industries"
  },
  "wafr_phases": {
    "overview": "There are three phases to conduct a successful Well-Architected Framework Review (WAFR)",
    "phases": [
      {
        "phase": 1,
        "name": "Prepare",
        "description": "Identify workload, sponsors, pillars, lens, format, and collect necessary data",
        "covered_in": "Part 1 of blog series"
      },
      {
        "phase": 2,
        "name": "Review",
        "description": "Conduct the actual review by answering questions and identifying risks",
        "covered_in": "Part 2 (this document)"
      },
      {
        "phase": 3,
        "name": "Improve",
        "description": "Create improvement plan to address identified risks",
        "covered_in": "Part 3 of blog series"
      }
    ],
    "preparation_checklist": [
      "✅ Identified the workload to review",
      "✅ Identified sponsors",
      "✅ Decided on pillars to review and their priority",
      "✅ Decided on what lens to use (if any)",
      "✅ Decided on format of review session",
      "✅ Collected necessary data on workload to answer review questions"
    ]
  },
  "wafr_goal": {
    "ultimate_goal": "Improve systems architectures so that these systems can better support business needs",
    "process": {
      "step_1": "Review current architecture against best practices by answering review questions",
      "step_2": "Identify areas to improve (High-Risk Issues and Medium-Risk Issues)",
      "step_3": "Create treatment plan to remediate risks using priority-based approach"
    },
    "risk_categories": [
      {
        "category": "HRI",
        "full_name": "High-Risk Issues",
        "priority": "Critical",
        "description": "Significant risks that need immediate attention"
      },
      {
        "category": "MRI",
        "full_name": "Medium-Risk Issues",
        "priority": "Important",
        "description": "Moderate risks that should be addressed in improvement plan"
      }
    ]
  },
  "best_practices": {
    "practice_1": {
      "name": "Set Expectations",
      "description": "WAFR is a big-time commitment for all participants",
      "recommendations": [
        "Have conversation with main stakeholders in advance",
        "Clarify expectations and roles before, during, and after the review",
        "Get stakeholder support upfront",
        "Ensure time commitment is understood"
      ],
      "why_important": "Without proper expectations, reviews can be seen as low priority or a burden rather than a valuable improvement opportunity"
    },
    "practice_2": {
      "name": "Conversations, Not Audits",
      "description": "Best results come when WAFR sessions are conversations, not checklists or scoring exercises",
      "recommendations": [
        "Encourage open dialogue about systems",
        "Avoid blame for missing best practices",
        "Create psychologically safe environment",
        "Focus on learning and improvement, not scoring"
      ],
      "benefits": [
        "Team members speak openly about their systems",
        "Helps uncover architectural risks that might be hidden",
        "Promotes honest assessment rather than defensive posturing",
        "Builds trust and collaboration"
      ],
      "anti_pattern": "Treating WAFR as a checklist or audit where teams feel judged"
    },
    "practice_3": {
      "name": "Team Sport - Everyone Plays a Role",
      "description": "All team members should have specific roles and responsibilities",
      "roles": [
        {
          "role": "Pillar Sponsor",
          "responsibilities": [
            "Ensure all questions in the pillar are answered correctly",
            "Own the improvement plan for risks identified during review",
            "Lead remediation efforts for their pillar"
          ]
        },
        {
          "role": "Workload Owner",
          "responsibilities": [
            "Provide architectural context",
            "Answer technical questions",
            "Coordinate with pillar sponsors"
          ]
        },
        {
          "role": "Technical SMEs",
          "responsibilities": [
            "Provide deep technical expertise",
            "Validate best practice implementation",
            "Suggest remediation approaches"
          ]
        }
      ],
      "why_important": "Distributed ownership ensures accountability and makes improvement phase more effective"
    },
    "practice_4": {
      "name": "Continuous Check, Not One-Time Effort",
      "description": "Things always change and should be kept in check",
      "recommendations": [
        "Conduct WAFR on regular basis (e.g., quarterly, semi-annually)",
        "Review following big milestones in workload lifecycle",
        "Create milestone when transitioning environments (Test → Production)",
        "Establish organizational practice for regular reviews"
      ],
      "lifecycle_triggers": [
        "Initial design phase",
        "Before production launch",
        "After production launch (30/60/90 days)",
        "Major architecture changes",
        "New feature additions",
        "Scaling events",
        "Security incidents",
        "Cost optimization initiatives"
      ],
      "benefits": [
        "Catch architectural drift early",
        "Ensure best practices are maintained",
        "Track improvement progress over time",
        "Adapt to changing business needs"
      ]
    },
    "practice_5": {
      "name": "Earlier Is Better",
      "description": "Easier to influence decisions and drive changes in design phase vs production",
      "recommendations": [
        "Conduct WAFR during design phase",
        "Review architecture before implementation",
        "Identify risks before they become expensive to fix"
      ],
      "cost_of_change_curve": {
        "design_phase": "Low cost to change",
        "development_phase": "Moderate cost to change",
        "testing_phase": "High cost to change",
        "production_phase": "Very high cost to change"
      },
      "benefits": [
        "Lower cost of remediation",
        "Faster implementation of changes",
        "Avoid technical debt",
        "Better architectural decisions"
      ]
    },
    "practice_6": {
      "name": "Use AWS Well-Architected Tool",
      "description": "WAFR questions available as whitepaper, but tool provides significant advantages",
      "tool_benefits": [
        "Track questions and answers",
        "Take notes per question",
        "Create different milestones",
        "Understand question context",
        "Understand best practice being validated",
        "Explore additional resources (blogs, re:Invent talks, documentation)",
        "Generate reports",
        "Share workloads with team members"
      ],
      "custom_lenses": {
        "description": "Create your own pillars, questions, and best practices",
        "use_cases": [
          "Technology-specific questions (e.g., Kubernetes, Serverless)",
          "Industry-specific requirements (e.g., FinTech, Healthcare)",
          "Organization-specific governance",
          "Regulatory compliance (e.g., HIPAA, PCI-DSS, GDPR)"
        ],
        "resources": [
          {
            "title": "Customize Well-Architected Reviews using Custom Lenses and the AWS Well-Architected Tool",
            "type": "Blog post"
          },
          {
            "title": "Implementing the AWS Well-Architected Custom Lens lifecycle in your organization",
            "type": "Blog post"
          },
          {
            "title": "Best Practices for the Custom Lens Lifecycle: Plan and Implement",
            "type": "Blog post"
          },
          {
            "title": "Best Practices for the Custom Lens Lifecycle: Measure and Improve",
            "type": "Blog post"
          }
        ]
      },
      "note_taking": {
        "when_implemented": "Tick checkbox in the question",
        "when_not_implemented": {
          "action": "Take note in notes area explaining why",
          "questions_to_answer": [
            "Is it on the roadmap?",
            "Does it conflict with other requirements?",
            "Is it simply missed?",
            "What are the blockers?"
          ]
        },
        "benefits": [
          "Helps team later in creating improvement plan",
          "Helps other reviewers as teams/owners may change",
          "Provides context for future reviews",
          "Documents decision rationale"
        ]
      },
      "milestones": {
        "definition": "Records the state of a workload at a particular point in time",
        "use_cases": [
          "Multiple review sessions",
          "After working on improvement items",
          "Measure progress over time",
          "Compare before/after states"
        ],
        "recommendation": "Save milestone after each review or major improvement cycle"
      }
    },
    "practice_7": {
      "name": "Maximize Time",
      "description": "WAFR should be short and completed in hours, not days",
      "time_management": {
        "goal": "Keep review concise while thorough",
        "balance": "Between asking follow-up questions and staying within question context",
        "avoid": "Deep technical discussions during review"
      },
      "context_awareness": {
        "example": "Monitoring appears across all six pillars but context varies",
        "operational_excellence_context": "Observability, understanding workload health, establishing metrics and KPIs",
        "security_context": "Auditing environments, tracing malicious activities, understanding unauthorized behavior"
      },
      "what_to_avoid": [
        {
          "anti_pattern": "Deep technical discussions",
          "example": "Going into detailed service configuration",
          "recommendation": "Take notes, follow up in Improve phase"
        },
        {
          "anti_pattern": "Solution discussions during review",
          "reason": "Not enough time and details to recommend right solution on the spot",
          "recommendation": "Document as improvement item, address in Improve phase with proper research"
        }
      ],
      "recommended_duration": {
        "per_pillar": "1-2 hours",
        "full_review_6_pillars": "6-12 hours (spread over multiple sessions)",
        "focused_review_2_3_pillars": "2-6 hours"
      }
    },
    "practice_8": {
      "name": "Maybe Is No",
      "description": "If team is not sure if best practice is implemented, consider it not implemented",
      "rule": "Uncertainty = Not Implemented",
      "process": [
        "Team unsure if best practice is implemented?",
        "Consider it NOT implemented",
        "Document uncertainty in notes in WA Tool",
        "Include validation (or implementation) as follow-up in improvement phase"
      ],
      "rationale": [
        "Better to be conservative in assessment",
        "If you can't confirm it's implemented, it may not be working as intended",
        "Prevents false confidence in architecture",
        "Ensures thorough validation in improvement phase"
      ],
      "example": {
        "question": "Do you have automated backup and recovery testing?",
        "team_response": "We think so, but not 100% sure",
        "action": "Mark as NOT IMPLEMENTED",
        "notes": "Team unsure if backup testing is automated. Need to validate with ops team and review automation scripts.",
        "improvement_item": "Validate backup testing automation and implement if missing"
      }
    },
    "practice_9": {
      "name": "Scale and Automate as Necessary",
      "description": "For large organizations with many workloads, build automated and scalable processes",
      "when_to_automate": [
        "Reviewing 10+ workloads",
        "Multiple teams conducting reviews",
        "Regular review cadence (quarterly for 50+ workloads)",
        "Organization-wide WAFR program",
        "Compliance requirements for all workloads"
      ],
      "automation_capabilities": [
        "Automated workload creation",
        "Programmatic question answering",
        "Risk identification and aggregation",
        "Centralized reporting",
        "Trend analysis across workloads",
        "Risk remediation tracking"
      ]
    }
  },
  "automation_examples": {
    "example_1": {
      "title": "Create and update Well-Architected reviews using AWS CloudFormation",
      "type": "Lab",
      "use_case": "Infrastructure as Code integration",
      "description": "Automate workload creation and updates via CloudFormation"
    },
    "example_2": {
      "title": "Build custom reports of Well-Architected Review",
      "type": "Lab",
      "use_case": "Centralized reporting",
      "description": "Integrate AWS Well-Architected data into centralized reporting tools using WA Tool API"
    },
    "example_3": {
      "title": "Scaling AWS Well-Architected Reviews through the enterprise",
      "type": "re:Invent 2022 session",
      "use_case": "Enterprise-scale standardization",
      "description": "Create standardized and consistent approach to reviewing workloads and building scalable architectural health reporting"
    },
    "example_4": {
      "title": "Cloud optimization with Trusted Advisor and AWS Well-Architected Tool",
      "type": "re:Invent 2022 session",
      "use_case": "Integration with Trusted Advisor",
      "description": "Integrate AWS Well-Architected Framework, WA Tool, and Trusted Advisor to identify cloud optimization opportunities"
    },
    "example_5": {
      "title": "AWS Well-Architected best practices for DevOps on AWS",
      "type": "re:Invent 2022 session",
      "use_case": "DevOps alignment",
      "description": "Align organization's DevOps practices to pillars of AWS Well-Architected Framework"
    },
    "example_6": {
      "title": "Accelerating Well-Architected Framework reviews using integrated AWS Trusted Advisor insights",
      "type": "Blog post",
      "use_case": "Accelerated reviews with TA integration",
      "description": "Pre-populate answers and accelerate reviews using Trusted Advisor data"
    }
  },
  "integration_with_automation_platform": {
    "practice_alignment": {
      "conversational_approach": {
        "how_your_platform_helps": "Your Discovery Agent conducts conversational WAFR via chat, not checklist-style audit",
        "benefit": "Natural, non-threatening dialogue that encourages honest responses"
      },
      "team_sport": {
        "how_your_platform_helps": "Orchestrator Agent coordinates multiple specialized agents (Discovery, Assessment, Validation, Report), each with specific responsibilities",
        "benefit": "Distributed expertise mirrors pillar sponsor model"
      },
      "continuous_check": {
        "how_your_platform_helps": "Programmatic workload creation + milestone automation enables regular reviews at scale",
        "benefit": "Easy to schedule quarterly reviews for all workloads"
      },
      "maximize_time": {
        "how_your_platform_helps": "Assessment Agent pre-answers questions using AWS APIs (Config, Security Hub, Trusted Advisor), reducing review time from hours to minutes",
        "benefit": "Stakeholders only need to validate pre-populated answers, not answer from scratch"
      },
      "scale_and_automate": {
        "how_your_platform_helps": "Your entire platform is the automation solution for large-scale WAFR programs",
        "benefit": "Can conduct 100+ reviews per month with minimal human effort"
      }
    },
    "enhanced_workflow_with_best_practices": {
      "step_1_prepare": {
        "agent": "Discovery Agent",
        "actions": [
          "Conduct conversational discovery (Practice #2: Conversations, not audits)",
          "Identify workload, sponsors, pillars (from Part 1 preparation)",
          "Set expectations about time commitment (Practice #1)",
          "Create workload in WA Tool via API"
        ]
      },
      "step_2_review": {
        "agent": "Assessment Agent",
        "actions": [
          "For each question, assess via AWS APIs (Practice #6: Use WA Tool)",
          "Apply 'Maybe is No' rule (Practice #8)",
          "Take detailed notes explaining answers (Practice #6: Note-taking)",
          "Update answers in WA Tool via API",
          "Keep review focused, avoid deep technical discussions (Practice #7: Maximize time)"
        ]
      },
      "step_3_validate": {
        "agent": "Validation Agent",
        "actions": [
          "Cross-check answers with AWS Config rules",
          "Verify best practice implementation",
          "Apply 'Maybe is No' rule for uncertain answers"
        ]
      },
      "step_4_milestone": {
        "agent": "Report Agent",
        "actions": [
          "Create milestone to capture workload state (Practice #6: Milestones)",
          "Enable continuous tracking over time (Practice #4: Continuous check)"
        ]
      },
      "step_5_report": {
        "agent": "Report Agent",
        "actions": [
          "Generate official AWS report + custom enhanced report",
          "Identify HRIs and MRIs",
          "Prepare for Improve phase (Part 3)"
        ]
      }
    }
  },
  "anti_patterns_to_avoid": {
    "anti_pattern_1": {
      "pattern": "Treating WAFR as a one-time compliance checkbox",
      "why_bad": "Architecture and best practices evolve; single review provides no ongoing value",
      "correction": "Establish regular review cadence (Practice #4: Continuous check)"
    },
    "anti_pattern_2": {
      "pattern": "Audit-style review that blames teams for gaps",
      "why_bad": "Creates defensive posture, hides real risks, damages team morale",
      "correction": "Conversational approach focused on improvement, not blame (Practice #2)"
    },
    "anti_pattern_3": {
      "pattern": "Single person conducting entire review",
      "why_bad": "Lacks diverse perspectives, creates bottleneck, no distributed ownership",
      "correction": "Team sport with defined roles and responsibilities (Practice #3)"
    },
    "anti_pattern_4": {
      "pattern": "Multi-day deep-dive technical sessions",
      "why_bad": "Review phase drags on, loses momentum, doesn't scale",
      "correction": "Keep review concise (hours, not days), defer deep technical discussions (Practice #7)"
    },
    "anti_pattern_5": {
      "pattern": "Assuming best practices are implemented without validation",
      "why_bad": "Creates false confidence, risks go undetected",
      "correction": "Apply 'Maybe is No' rule (Practice #8)"
    },
    "anti_pattern_6": {
      "pattern": "Only reviewing production workloads",
      "why_bad": "Misses opportunity for low-cost fixes during design/development",
      "correction": "Review early in lifecycle, ideally during design (Practice #5)"
    },
    "anti_pattern_7": {
      "pattern": "Manual reviews for 50+ workloads with no automation",
      "why_bad": "Doesn't scale, inconsistent quality, high cost",
      "correction": "Build automated processes for large organizations (Practice #9)"
    }
  },
  "pillar_context_awareness": {
    "concept": "Same topic appears across pillars but with different context",
    "example_monitoring": {
      "topic": "Monitoring",
      "operational_excellence_context": {
        "focus": "Observability and workload health",
        "key_questions": [
          "What metrics and KPIs are you tracking?",
          "How do you understand workload health?",
          "What dashboards do you have?",
          "How do you respond to operational events?"
        ]
      },
      "security_context": {
        "focus": "Auditing and threat detection",
        "key_questions": [
          "What are you auditing?",
          "How do you trace malicious activities?",
          "How do you detect unauthorized behavior?",
          "What security alerts do you have?"
        ]
      },
      "reliability_context": {
        "focus": "Failure detection and recovery",
        "key_questions": [
          "How do you detect failures?",
          "What are your availability metrics?",
          "How do you monitor dependencies?",
          "How do you alert on SLA breaches?"
        ]
      },
      "performance_context": {
        "focus": "Performance metrics and optimization",
        "key_questions": [
          "What performance metrics do you track?",
          "How do you detect performance degradation?",
          "How do you monitor resource utilization?",
          "What are your latency targets?"
        ]
      },
      "cost_optimization_context": {
        "focus": "Cost visibility and tracking",
        "key_questions": [
          "How do you track costs?",
          "What cost anomalies do you monitor?",
          "How do you attribute costs to business units?",
          "What cost optimization metrics do you use?"
        ]
      },
      "sustainability_context": {
        "focus": "Environmental impact metrics",
        "key_questions": [
          "How do you measure carbon footprint?",
          "What sustainability metrics do you track?",
          "How do you monitor resource efficiency?",
          "What sustainability KPIs do you report?"
        ]
      }
    },
    "recommendation": "Keep questions within pillar context, acknowledge cross-pillar topics but maintain focus"
  },
  "time_saving_strategies": {
    "strategy_1": {
      "name": "Pre-populate answers using AWS APIs",
      "description": "Use AWS Config, Security Hub, Trusted Advisor to answer questions before review session",
      "time_saved": "50-70% reduction in review time",
      "implementation": "Your Assessment Agent already does this!"
    },
    "strategy_2": {
      "name": "Focus on unanswered and high-risk questions",
      "description": "Pre-answered questions with 'NONE' risk can be quickly validated, focus time on unanswered or risky areas",
      "time_saved": "30-40% reduction in review time"
    },
    "strategy_3": {
      "name": "Use profiles to prioritize questions",
      "description": "Apply organizational profile to focus on business-critical questions first",
      "time_saved": "Review only 15-20 prioritized questions instead of 50+ total questions",
      "implementation": "Use WA Tool Profiles feature"
    },
    "strategy_4": {
      "name": "Asynchronous pre-review",
      "description": "Share pre-populated answers with team before live session, use live session only for validation and discussion",
      "time_saved": "Live session reduced from 8 hours to 2-3 hours"
    }
  },
  "success_metrics": {
    "review_phase_metrics": [
      {
        "metric": "Time to Complete Review",
        "target": "Hours, not days per workload",
        "measurement": "From start to all questions answered"
      },
      {
        "metric": "Question Completion Rate",
        "target": "100% of questions answered (including 'Not Applicable')",
        "measurement": "Answered questions / Total questions"
      },
      {
        "metric": "Risk Identification Rate",
        "target": "All HRIs and MRIs identified",
        "measurement": "Number of HRIs + MRIs identified"
      },
      {
        "metric": "Note Quality",
        "target": "All 'No' answers have detailed notes explaining why",
        "measurement": "Percentage of 'No' answers with notes"
      },
      {
        "metric": "Team Participation",
        "target": "All key stakeholders participate actively",
        "measurement": "Participation rate, engagement score"
      },
      {
        "metric": "Milestone Creation",
        "target": "Milestone saved after review completion",
        "measurement": "Boolean: milestone exists"
      }
    ]
  },
  "key_takeaways": [
    "WAFR Review phase is about identifying architectural risks by comparing current state to best practices",
    "Reviews should be conversational, honest, documented, and completed in hours (not weeks)",
    "Use AWS Well-Architected Tool for tracking, notes, milestones, and context",
    "Apply 'Maybe is No' rule to avoid false confidence",
    "Keep reviews focused; defer deep technical discussions to Improve phase",
    "For large organizations, automate and scale the review process",
    "Review earlier in lifecycle for lower cost of change",
    "Establish continuous review practice, not one-time effort",
    "Team sport: everyone has a role and owns part of improvement plan"
  ],
  "next_phase": {
    "phase": "Improve (Part 3)",
    "description": "After identifying risks (HRIs and MRIs), create improvement plan to address them",
    "covered_in": "Part 3 of blog series"
  }
}

